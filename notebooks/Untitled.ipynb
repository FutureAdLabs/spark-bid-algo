{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d45979-a1ae-4227-a2b4-bb04027e1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys, os\n",
    "\n",
    "from spark.connection import createSparkConnection, closeSparkConnection\n",
    "from athena_connection import AthenaConnection\n",
    "\n",
    "from components.transformers.score_transformer import Score_T\n",
    "from components.transformers.parameters.score_parameters import *\n",
    "\n",
    "from model.score import adlogdata\n",
    "from model.config import adconfig\n",
    "from model.bid import admodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1906f20-7a9f-4328-9cfa-4dffc8bf6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparkPipeline():\n",
    "    ''' \n",
    "    spark pipeline helper class\n",
    "    '''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.filter_by = kwargs.get('filter_by','campaign_id')\n",
    "        self.filters = kwargs.get('filters','fdbieo5')\n",
    "        self.start_date = kwargs.get('start_date','2022-01-10')\n",
    "        self.end_date = kwargs.get('end_date', '2022-01-11')\n",
    "    \n",
    "    # def getPathFromAthena(self):\n",
    "    #     path = AthenaConnection()\n",
    "    #     print(f'ATHENA FILE PATH == {path}')\n",
    "\n",
    "    #     return path\n",
    "\n",
    "    def getData(self, file_path=None, file_type=None):\n",
    "        if file_path is None:\n",
    "            c = AthenaConnection()\n",
    "            print(c)\n",
    "            c.getS3Path()\n",
    "            print(f'ATHENA FILE PATH == {file_path}')\n",
    "        if file_type is None:\n",
    "            file_type = 'csv'\n",
    "\n",
    "        return file_path\n",
    "\n",
    "    # def createSparkConnection(self):\n",
    "    #     spark= SparkConnection()\n",
    "\n",
    "    #     return spark\n",
    "\n",
    "    def loadFile(self, df, file_path, file_type, partitions):\n",
    "        df.write\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .partitionBy(partitions)\\\n",
    "        .file_type(file_path)\n",
    "\n",
    "    def score_data(self, *kwargs):\n",
    "\n",
    "        # get input data for scoring\n",
    "        # self.getPathFromAthena()\n",
    "        \n",
    "        file_path  = self.getData()\n",
    "\n",
    "        # create connection\n",
    "        self.spark = createSparkConnection()\n",
    "        # self.sc = self.spark.sparkContext\n",
    "\n",
    "        print(f'SPARK SESSION =  {self.spark}')\n",
    "        # print(F'SPARK CONTEXT = {self.sc}')\n",
    "\n",
    "        df = self.spark.read.format('csv')\\\n",
    "        .options(header='true', inferSchema='true')\\\n",
    "        .load(file_path)\n",
    "\n",
    "\n",
    "        # score data\n",
    "        score = Score_T(kpi='ER',\n",
    "                        modelParams=self.model_params,\n",
    "                        verbose=2,\n",
    "                        mutualInformation=False)\n",
    "\n",
    "        df_scored = self.df.transform(score.transform)\n",
    "\n",
    "        # save scored file\n",
    "        self.loadFile(df_scored)\n",
    "        score = Score_T.transform(self, self.df)\n",
    "        \n",
    "        print(score)\n",
    "\n",
    "        # print(df_scored)\n",
    "        \n",
    "        return df_scored\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    c = SparkPipeline()\n",
    "    c.score_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03ffa9-34de-4f9c-bc8e-868a10527efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d23542-2e87-4556-871a-84f52e193c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7664e-bc1a-4542-83cf-f9c7b0153c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:algos]",
   "language": "python",
   "name": "conda-env-algos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
